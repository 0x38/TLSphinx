# TLSphinx

TLSphinx is a Swift wrapper around [Pocketsphinx], a portable library based on [CMU Sphinx], that allow an application to perform speech recognition **withouth the audio leave the device**

This repository has two main parts. First is syntetized version of the [pocketsphinx](http://sourceforge.net/projects/cmusphinx/files/pocketsphinx/5prealpha/) and [sphinx base] repositories with a module map to access the library as a [Clang module]. This module is accessed under the name `Shpinx` and has two submodules: `Pocket` and `Base` in reference to _pocketsphinx_ and _sphinx base_.

The second part is `TLSphinx`, a Swift framework that use the `Sphinx` Clang module and expose a Swift-like API that talks to _pocketsphinx_.

## Usage

Right now the only supported operation is decode the speech in an audio file. To do so you first need to create a `Config` object. This object represents the _cmd_ln_t_ opaque structure and accept the same parameters in his default constructor.

Once a `Config` object is created you need to create a `Decoder` passing in you configuration object. With the decoder you can perform automatic speech recognition from an audio file like this:

```swift
import TLSphinx

let hmm = ...   // Path to the acustic model
let lm = ...    // Path to the languaje model
let dict = ...  // Path to the languaje dictionary

if let config = Config(args: ("-hmm", hmm), ("-lm", lm), ("-dict", dict)) {
  if let decoder = Decoder(config:config) {
      
      let audioFile = ... // Path to an audio file
      
      decoder.decodeSpeechAtPath(audioFile) {
          
          if let hyp: Hypotesis = $0 {
              // Print the decoder text and score
              println("Text: \(hyp.text) - Score: \(hyp.score)")
          } else {
              // Can't decode any speech because an error
          }
      }
  } else {
      // Handle Decoder() fail
  }
} else {
  // Handle Config() fail  
}
```

The `Config` constructor take an array of tuples with the form `(param name, param value)` where _"param name"_ is the name of one of the parameters recognized for _Sphinx_. In this example we are passing the acustic model, the languaje model and the dictionary. For a complete list of recognized parameters check the [Sphinx docs].

Then the example create a `Decoder` to process an audio file. The audio must have be, as expresed in the Pocketsphinx tutorial,  _"single-channel (monaural), little-endian, unheadered 16-bit signed PCM audio file sampled at 16000 Hz"_. The decode is performed with the `decodeSpeechAtPath` function in the bacground. It receive two parameters: the audio file path and a closure that will receive the result once the process finish. Once the decode process finish the `complete` closure is called in the main thread.

```swift
public func decodeSpeechAtPath (filePath: String, complete: (Hypotesis?) -> ())
```

The result of the decode process is a `Hypotesis` value _(it's actualy a `Optional<Hypotesis>`)_ following the naming convention of the _Pocketsphinx_ API. `Hypotesis` is an struct with two fields:
- `text` is the text recognized in the audio
- `score` is a numeric score of the hypotesis

The `Decoder` has a public property `bufferSize: Int` to control the size of the buffer used to read the audio file. Also the `Config` class has a `showDebugInfo: Bool` property to turn on/off the messages generated by the _Sphinx_ library on run time.


[CMU Sphinx]: http://cmusphinx.sourceforge.net/
[Pocketsphinx]: http://cmusphinx.sourceforge.net/wiki/tutorialpocketsphinx
[sphinx base]: http://sourceforge.net/projects/cmusphinx/files/sphinxbase/5prealpha/
[Clang module]: http://clang.llvm.org/docs/Modules.html
[Sphinx docs]: http://cmusphinx.sourceforge.net/wiki/
